{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 222,
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "from timeit import default_timer as timer # Time how long commands take\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # Ignore warnings to clean up visual output change back to 'default' to see them\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create fake data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "outputs": [],
   "source": [
    "row_num = 5000"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "outputs": [],
   "source": [
    "# Create columns names for dataset\n",
    "columns = [''.join(random.choices(string.ascii_uppercase + string.digits, k=5)) for x in range(380)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [],
   "source": [
    "# Add Thyroid cancer to columns\n",
    "columns.insert(0, 'userId')\n",
    "# Add userId to columns\n",
    "columns.append('thyroid_cancer')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [],
   "source": [
    "# Create dataframe rows with different possible data types\n",
    "\n",
    "dictionary = {}\n",
    "\n",
    "for item in columns:\n",
    "\n",
    "    column_options = [[random.randint(0,1) for i in range(row_num)], np.random.randint(0, 10, row_num, dtype=int), np.random.randint(0, 3, row_num, dtype=int),\n",
    "                      np.random.random_sample(size = row_num), np.random.uniform(low=0, high=3000, size=row_num), np.random.uniform(low=0, high=150, size=row_num)]\n",
    "\n",
    "    dictionary[item] = random.choice(column_options)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [],
   "source": [
    "# Create the pandas DataFrame\n",
    "df = pd.DataFrame(dictionary)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "outputs": [],
   "source": [
    "# Change userId values\n",
    "df['userId'] = [x for x in range(row_num)]\n",
    "\n",
    "# Make userId index\n",
    "df.set_index('userId', inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [],
   "source": [
    "# Add missing values\n",
    "for col in df.columns:\n",
    "    df.loc[df.sample(frac=0.1).index, col] = np.nan"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [],
   "source": [
    "# Make thyroid cancer data binary with no missing values\n",
    "df['thyroid_cancer'] = [random.randint(0, 1) for x in range(row_num)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Manual Preprocessing - UK Biobank ThyCa specific"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "outputs": [],
   "source": [
    "# Make sure thyroid cancer column has been added"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "outputs": [],
   "source": [
    "# Make sure diseases descriptions are the column names rather than just phecodes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "outputs": [],
   "source": [
    "# Manual feature selection - use mutual information and consider data leakage."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Exploration"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Missing Values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Target Class Imbalance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Summary Statistics (including boxplots) for Non-Binary Predictor Variables (Features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Correlation Matrices"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pairplots of Quantitative Variables"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Further Inspection of Correlated Variables"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test Train Split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Simple concept of splitting the data into two parts, one part for training the model and the other for testing the success of the model. Read more about the details [here](https://towardsdatascience.com/understanding-train-test-split-scikit-learn-python-ea676d5e3d1) and the sklearn documentation for it [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "outputs": [
    {
     "data": {
      "text/plain": "        QI8KX        EW5XJ       394MJ  5JCY6  N2TG9     MWSMR       M57ER  \\\nuserId                                                                       \n0         2.0   178.411894   64.271156    7.0    7.0  0.342611   79.245015   \n1         2.0    41.058191   67.988225    0.0    3.0  0.504474         NaN   \n2         1.0  1118.457041  147.822393    0.0    NaN  0.780437  134.648108   \n3         1.0  2690.553815  103.377883    3.0    3.0  0.291342  145.199941   \n4         0.0   615.266363   49.694446    1.0    4.0  0.123044   64.328732   \n...       ...          ...         ...    ...    ...       ...         ...   \n4995      2.0   364.680844         NaN    2.0    0.0  0.032761   38.924141   \n4996      1.0          NaN    1.225612    2.0    2.0  0.886880  110.135788   \n4997      0.0  1689.256828         NaN    6.0    0.0  0.019575   13.579529   \n4998      1.0  1469.869266   14.525267    8.0    5.0  0.057964   79.890496   \n4999      2.0  1989.110768  102.088126    3.0    3.0  0.105994   76.325049   \n\n        U0DHH  RWCWO  MAR0D  ...  W18UI  ANLUA        66BMD       DKW6X  \\\nuserId                       ...                                          \n0         0.0    1.0    1.0  ...    6.0    4.0  2645.203075   54.583515   \n1         1.0    0.0    2.0  ...    8.0    7.0   180.707016   41.534475   \n2         1.0    1.0    2.0  ...    NaN    1.0  2083.378063  105.312080   \n3         2.0    1.0    0.0  ...    9.0    NaN  2405.162930         NaN   \n4         0.0    1.0    0.0  ...    9.0    9.0  1506.176535   88.040958   \n...       ...    ...    ...  ...    ...    ...          ...         ...   \n4995      2.0    0.0    0.0  ...    2.0    1.0   430.500069  107.329729   \n4996      2.0    1.0    0.0  ...    9.0    6.0    59.799045         NaN   \n4997      1.0    1.0    2.0  ...    3.0    8.0   301.623017   73.243115   \n4998      2.0    0.0    2.0  ...    2.0    1.0  2628.951744   57.886503   \n4999      NaN    1.0    0.0  ...    6.0    2.0  2605.208489   70.326080   \n\n              UB65D  G1106       Z55FK  5LZSG        0XI7C  thyroid_cancer  \nuserId                                                                      \n0       2764.888478    0.0  138.187447    1.0  2285.403528               0  \n1       2620.283367    1.0   37.911595    0.0  2262.750325               1  \n2        501.798643    1.0  128.040195    0.0  1650.003516               0  \n3       2435.913390    1.0   11.145034    0.0          NaN               1  \n4       1165.386309    0.0   74.357761    1.0  1292.899258               1  \n...             ...    ...         ...    ...          ...             ...  \n4995     214.951819    0.0  127.465821    1.0  2432.780735               1  \n4996    1397.923996    1.0   62.060686    0.0  2388.699113               1  \n4997    2118.443840    1.0   98.669090    0.0   650.083062               0  \n4998            NaN    0.0    6.390604    0.0  1864.882744               1  \n4999    1033.595758    0.0  122.065977    1.0  2098.200232               1  \n\n[5000 rows x 381 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>QI8KX</th>\n      <th>EW5XJ</th>\n      <th>394MJ</th>\n      <th>5JCY6</th>\n      <th>N2TG9</th>\n      <th>MWSMR</th>\n      <th>M57ER</th>\n      <th>U0DHH</th>\n      <th>RWCWO</th>\n      <th>MAR0D</th>\n      <th>...</th>\n      <th>W18UI</th>\n      <th>ANLUA</th>\n      <th>66BMD</th>\n      <th>DKW6X</th>\n      <th>UB65D</th>\n      <th>G1106</th>\n      <th>Z55FK</th>\n      <th>5LZSG</th>\n      <th>0XI7C</th>\n      <th>thyroid_cancer</th>\n    </tr>\n    <tr>\n      <th>userId</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.0</td>\n      <td>178.411894</td>\n      <td>64.271156</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>0.342611</td>\n      <td>79.245015</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>6.0</td>\n      <td>4.0</td>\n      <td>2645.203075</td>\n      <td>54.583515</td>\n      <td>2764.888478</td>\n      <td>0.0</td>\n      <td>138.187447</td>\n      <td>1.0</td>\n      <td>2285.403528</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.0</td>\n      <td>41.058191</td>\n      <td>67.988225</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.504474</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>8.0</td>\n      <td>7.0</td>\n      <td>180.707016</td>\n      <td>41.534475</td>\n      <td>2620.283367</td>\n      <td>1.0</td>\n      <td>37.911595</td>\n      <td>0.0</td>\n      <td>2262.750325</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>1118.457041</td>\n      <td>147.822393</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.780437</td>\n      <td>134.648108</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>2083.378063</td>\n      <td>105.312080</td>\n      <td>501.798643</td>\n      <td>1.0</td>\n      <td>128.040195</td>\n      <td>0.0</td>\n      <td>1650.003516</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>2690.553815</td>\n      <td>103.377883</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>0.291342</td>\n      <td>145.199941</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>2405.162930</td>\n      <td>NaN</td>\n      <td>2435.913390</td>\n      <td>1.0</td>\n      <td>11.145034</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>615.266363</td>\n      <td>49.694446</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>0.123044</td>\n      <td>64.328732</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>1506.176535</td>\n      <td>88.040958</td>\n      <td>1165.386309</td>\n      <td>0.0</td>\n      <td>74.357761</td>\n      <td>1.0</td>\n      <td>1292.899258</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4995</th>\n      <td>2.0</td>\n      <td>364.680844</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.032761</td>\n      <td>38.924141</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>430.500069</td>\n      <td>107.329729</td>\n      <td>214.951819</td>\n      <td>0.0</td>\n      <td>127.465821</td>\n      <td>1.0</td>\n      <td>2432.780735</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4996</th>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.225612</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0.886880</td>\n      <td>110.135788</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>9.0</td>\n      <td>6.0</td>\n      <td>59.799045</td>\n      <td>NaN</td>\n      <td>1397.923996</td>\n      <td>1.0</td>\n      <td>62.060686</td>\n      <td>0.0</td>\n      <td>2388.699113</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4997</th>\n      <td>0.0</td>\n      <td>1689.256828</td>\n      <td>NaN</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>0.019575</td>\n      <td>13.579529</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>3.0</td>\n      <td>8.0</td>\n      <td>301.623017</td>\n      <td>73.243115</td>\n      <td>2118.443840</td>\n      <td>1.0</td>\n      <td>98.669090</td>\n      <td>0.0</td>\n      <td>650.083062</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4998</th>\n      <td>1.0</td>\n      <td>1469.869266</td>\n      <td>14.525267</td>\n      <td>8.0</td>\n      <td>5.0</td>\n      <td>0.057964</td>\n      <td>79.890496</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>2628.951744</td>\n      <td>57.886503</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>6.390604</td>\n      <td>0.0</td>\n      <td>1864.882744</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4999</th>\n      <td>2.0</td>\n      <td>1989.110768</td>\n      <td>102.088126</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>0.105994</td>\n      <td>76.325049</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>6.0</td>\n      <td>2.0</td>\n      <td>2605.208489</td>\n      <td>70.326080</td>\n      <td>1033.595758</td>\n      <td>0.0</td>\n      <td>122.065977</td>\n      <td>1.0</td>\n      <td>2098.200232</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5000 rows × 381 columns</p>\n</div>"
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at our data\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "outputs": [],
   "source": [
    "# Import sklearn function\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "outputs": [],
   "source": [
    "# Separate the features into the features and the target\n",
    "X = df.loc[:, df.columns != 'thyroid_cancer'] # Features\n",
    "y = df.loc[:, ['thyroid_cancer']] # Target"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, train_size = .8)\n",
    "# random_state is a number set to ensure same random split when re-run, the value itself does not matter just represents a split instance\n",
    "# If you want to test with different splits then change it of set it to none"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# One Hot Encoding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "outputs": [],
   "source": [
    "# Find categorical data columns in dataframe\n",
    "def find_categorical_columns(dataframe):\n",
    "\n",
    "    columns = [list(dataframe[i]) for i in dataframe]\n",
    "\n",
    "    uniques = [len(set([i for i in a if pd.notna(i)])) for a in columns] # Num of unique values in a column\n",
    "\n",
    "    categorical_indexes = [i for i, c in enumerate(uniques) if c <= 10]\n",
    "\n",
    "    unique_cat_num = [uniques[i] for i in categorical_indexes]\n",
    "\n",
    "    index_ncats = list(zip(categorical_indexes, unique_cat_num))\n",
    "\n",
    "    return index_ncats # return indexes of categorical data and the number of categories for that index\n",
    "\n",
    "# Remove binary columns from categorical column list\n",
    "def remove_binary(zipped_list):\n",
    "\n",
    "    new_list = [list(item) for item in zipped_list if item[1] != 2]\n",
    "\n",
    "    return new_list # Index first, cat num second\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "outputs": [],
   "source": [
    "# Find categorical columns\n",
    "zl = find_categorical_columns(df)\n",
    "# Remove binary categorical columns\n",
    "cats = remove_binary(zl)\n",
    "# List of categorical column indexes\n",
    "one_hot_col_indexes = [i[0] for i in cats]\n",
    "# List of column names\n",
    "cat_cols = [df.columns[x] for x in one_hot_col_indexes]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# create instance of one hot encoder\n",
    "enc = OneHotEncoder()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "outputs": [],
   "source": [
    "# One hot encode the data\n",
    "enc_data = enc.fit_transform(df[cat_cols]).toarray()\n",
    "# New column names\n",
    "enc_feat = enc.get_feature_names_out(cat_cols)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['QI8KX_0.0', 'QI8KX_1.0', 'QI8KX_2.0', ..., 'G1106_1.0',\n       'G1106_2.0', 'G1106_nan'], dtype=object)"
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_feat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0., 0., 1., ..., 0., 0., 0.],\n       [0., 0., 1., ..., 1., 0., 0.],\n       [0., 1., 0., ..., 1., 0., 0.],\n       ...,\n       [1., 0., 0., ..., 1., 0., 0.],\n       [0., 1., 0., ..., 0., 0., 0.],\n       [0., 0., 1., ..., 0., 0., 0.]])"
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [],
   "source": [
    "encoded_df = pd.DataFrame(enc_data, columns=enc_feat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "outputs": [
    {
     "data": {
      "text/plain": "      QI8KX_0.0  QI8KX_1.0  QI8KX_2.0  QI8KX_nan  5JCY6_0.0  5JCY6_1.0  \\\n0           0.0        0.0        1.0        0.0        0.0        0.0   \n1           0.0        0.0        1.0        0.0        1.0        0.0   \n2           0.0        1.0        0.0        0.0        1.0        0.0   \n3           0.0        1.0        0.0        0.0        0.0        0.0   \n4           1.0        0.0        0.0        0.0        0.0        1.0   \n...         ...        ...        ...        ...        ...        ...   \n4995        0.0        0.0        1.0        0.0        0.0        0.0   \n4996        0.0        1.0        0.0        0.0        0.0        0.0   \n4997        1.0        0.0        0.0        0.0        0.0        0.0   \n4998        0.0        1.0        0.0        0.0        0.0        0.0   \n4999        0.0        0.0        1.0        0.0        0.0        0.0   \n\n      5JCY6_2.0  5JCY6_3.0  5JCY6_4.0  5JCY6_5.0  ...  ANLUA_5.0  ANLUA_6.0  \\\n0           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n1           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n2           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n3           0.0        1.0        0.0        0.0  ...        0.0        0.0   \n4           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n...         ...        ...        ...        ...  ...        ...        ...   \n4995        1.0        0.0        0.0        0.0  ...        0.0        0.0   \n4996        1.0        0.0        0.0        0.0  ...        0.0        1.0   \n4997        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n4998        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n4999        0.0        1.0        0.0        0.0  ...        0.0        0.0   \n\n      ANLUA_7.0  ANLUA_8.0  ANLUA_9.0  ANLUA_nan  G1106_0.0  G1106_1.0  \\\n0           0.0        0.0        0.0        0.0        1.0        0.0   \n1           1.0        0.0        0.0        0.0        0.0        1.0   \n2           0.0        0.0        0.0        0.0        0.0        1.0   \n3           0.0        0.0        0.0        1.0        0.0        1.0   \n4           0.0        0.0        1.0        0.0        1.0        0.0   \n...         ...        ...        ...        ...        ...        ...   \n4995        0.0        0.0        0.0        0.0        1.0        0.0   \n4996        0.0        0.0        0.0        0.0        0.0        1.0   \n4997        0.0        1.0        0.0        0.0        0.0        1.0   \n4998        0.0        0.0        0.0        0.0        1.0        0.0   \n4999        0.0        0.0        0.0        0.0        1.0        0.0   \n\n      G1106_2.0  G1106_nan  \n0           0.0        0.0  \n1           0.0        0.0  \n2           0.0        0.0  \n3           0.0        0.0  \n4           0.0        0.0  \n...         ...        ...  \n4995        0.0        0.0  \n4996        0.0        0.0  \n4997        0.0        0.0  \n4998        0.0        0.0  \n4999        0.0        0.0  \n\n[5000 rows x 1090 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>QI8KX_0.0</th>\n      <th>QI8KX_1.0</th>\n      <th>QI8KX_2.0</th>\n      <th>QI8KX_nan</th>\n      <th>5JCY6_0.0</th>\n      <th>5JCY6_1.0</th>\n      <th>5JCY6_2.0</th>\n      <th>5JCY6_3.0</th>\n      <th>5JCY6_4.0</th>\n      <th>5JCY6_5.0</th>\n      <th>...</th>\n      <th>ANLUA_5.0</th>\n      <th>ANLUA_6.0</th>\n      <th>ANLUA_7.0</th>\n      <th>ANLUA_8.0</th>\n      <th>ANLUA_9.0</th>\n      <th>ANLUA_nan</th>\n      <th>G1106_0.0</th>\n      <th>G1106_1.0</th>\n      <th>G1106_2.0</th>\n      <th>G1106_nan</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4995</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4996</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4997</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4998</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4999</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5000 rows × 1090 columns</p>\n</div>"
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Imputation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Selecting MissForest Random Forest imputation as it has been described the most successful algorithm (like in this [paper](https://www.frontiersin.org/articles/10.3389/fdata.2021.693674/full)), its relatively low level of computational 'greedyness', and due to the fact it is nonparametric. Another description of how it works can also be found [here](https://betterdatascience.com/python-missforest-algorithm/).\n",
    "\n",
    "See the [documentation](https://github.com/epsilon-machine/missingpy) on github for further details on MissForest.\n",
    "\n",
    "A basic example of how to use it can be found [here](https://betterdatascience.com/python-missforest-algorithm/)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "outputs": [],
   "source": [
    "# Import required for missforest due to new sklearn version renaming\n",
    "import sklearn.neighbors._base\n",
    "sys.modules['sklearn.neighbors.base'] = sklearn.neighbors._base\n",
    "# Import package for MissForest\n",
    "from missingpy import MissForest"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Imputation time: 16.518515841666765 mins\n"
     ]
    }
   ],
   "source": [
    "# Initialise imputer\n",
    "imputer = MissForest(max_iter=5)\n",
    "\n",
    "# Test imputation on subset of dataframe\n",
    "s = timer()\n",
    "imputed = imputer.fit_transform(df[df.columns[0:100]], cat_vars=[x for x in one_hot_col_indexes if x < 100]) # Test on subset of dataframe\n",
    "e = timer()\n",
    "print(f'Imputation time: {(e - s)/60} mins')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "outputs": [
    {
     "data": {
      "text/plain": "      QI8KX        EW5XJ       394MJ  5JCY6  N2TG9     MWSMR       M57ER  \\\n0       2.0   178.411894   64.271156    7.0    7.0  0.342611   79.245015   \n1       2.0    41.058191   67.988225    0.0    3.0  0.504474   79.834724   \n2       1.0  1118.457041  147.822393    0.0    3.0  0.780437  134.648108   \n3       1.0  2690.553815  103.377883    3.0    3.0  0.291342  145.199941   \n4       0.0   615.266363   49.694446    1.0    4.0  0.123044   64.328732   \n...     ...          ...         ...    ...    ...       ...         ...   \n4995    2.0   364.680844   78.646507    2.0    0.0  0.032761   38.924141   \n4996    1.0  1613.558176    1.225612    2.0    2.0  0.886880  110.135788   \n4997    0.0  1689.256828   74.730057    6.0    0.0  0.019575   13.579529   \n4998    1.0  1469.869266   14.525267    8.0    5.0  0.057964   79.890496   \n4999    2.0  1989.110768  102.088126    3.0    3.0  0.105994   76.325049   \n\n      U0DHH  RWCWO  MAR0D  ...  Y3K0J     P97EB  6IAMA       FQ2EP  PT1HK  \\\n0       0.0    1.0    1.0  ...    6.0  0.996116    2.0    9.397782    2.0   \n1       1.0    0.0    2.0  ...    7.0  0.543821    0.0   93.616651    0.0   \n2       1.0    1.0    2.0  ...    2.0  0.494028    1.0   14.240045    0.0   \n3       2.0    1.0    0.0  ...    4.0  0.001430    0.0   11.934569    1.0   \n4       0.0    1.0    0.0  ...    1.0  0.684642    1.0  131.100466    2.0   \n...     ...    ...    ...  ...    ...       ...    ...         ...    ...   \n4995    2.0    0.0    0.0  ...    7.0  0.750833    2.0  140.076844    2.0   \n4996    2.0    1.0    0.0  ...    7.0  0.297160    1.0   82.222408    1.0   \n4997    1.0    1.0    2.0  ...    2.0  0.596576    2.0   86.134989    2.0   \n4998    2.0    0.0    2.0  ...    9.0  0.528380    1.0  145.756246    0.0   \n4999    1.0    1.0    0.0  ...    6.0  0.563023    0.0  144.471874    2.0   \n\n      AYUOY     WBN7F  HG7C0  TUQX1       B1OIL  \n0       0.0  0.498976    1.0    2.0  103.285235  \n1       1.0  0.589777    1.0    0.0   21.555428  \n2       1.0  0.572293    1.0    1.0   96.054583  \n3       2.0  0.723056    0.0    1.0   53.042763  \n4       0.0  0.455917    0.0    1.0  104.397814  \n...     ...       ...    ...    ...         ...  \n4995    0.0  0.725573    0.0    2.0    0.668651  \n4996    2.0  0.673923    1.0    2.0   44.011999  \n4997    0.0  0.661564    1.0    0.0   22.645691  \n4998    1.0  0.553282    0.0    0.0   27.741351  \n4999    2.0  0.557232    1.0    2.0  117.808088  \n\n[5000 rows x 100 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>QI8KX</th>\n      <th>EW5XJ</th>\n      <th>394MJ</th>\n      <th>5JCY6</th>\n      <th>N2TG9</th>\n      <th>MWSMR</th>\n      <th>M57ER</th>\n      <th>U0DHH</th>\n      <th>RWCWO</th>\n      <th>MAR0D</th>\n      <th>...</th>\n      <th>Y3K0J</th>\n      <th>P97EB</th>\n      <th>6IAMA</th>\n      <th>FQ2EP</th>\n      <th>PT1HK</th>\n      <th>AYUOY</th>\n      <th>WBN7F</th>\n      <th>HG7C0</th>\n      <th>TUQX1</th>\n      <th>B1OIL</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.0</td>\n      <td>178.411894</td>\n      <td>64.271156</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>0.342611</td>\n      <td>79.245015</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>6.0</td>\n      <td>0.996116</td>\n      <td>2.0</td>\n      <td>9.397782</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.498976</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>103.285235</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.0</td>\n      <td>41.058191</td>\n      <td>67.988225</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.504474</td>\n      <td>79.834724</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>7.0</td>\n      <td>0.543821</td>\n      <td>0.0</td>\n      <td>93.616651</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.589777</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>21.555428</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>1118.457041</td>\n      <td>147.822393</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.780437</td>\n      <td>134.648108</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>0.494028</td>\n      <td>1.0</td>\n      <td>14.240045</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.572293</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>96.054583</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>2690.553815</td>\n      <td>103.377883</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>0.291342</td>\n      <td>145.199941</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>4.0</td>\n      <td>0.001430</td>\n      <td>0.0</td>\n      <td>11.934569</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0.723056</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>53.042763</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>615.266363</td>\n      <td>49.694446</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>0.123044</td>\n      <td>64.328732</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.684642</td>\n      <td>1.0</td>\n      <td>131.100466</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.455917</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>104.397814</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4995</th>\n      <td>2.0</td>\n      <td>364.680844</td>\n      <td>78.646507</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.032761</td>\n      <td>38.924141</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>7.0</td>\n      <td>0.750833</td>\n      <td>2.0</td>\n      <td>140.076844</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.725573</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.668651</td>\n    </tr>\n    <tr>\n      <th>4996</th>\n      <td>1.0</td>\n      <td>1613.558176</td>\n      <td>1.225612</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0.886880</td>\n      <td>110.135788</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>7.0</td>\n      <td>0.297160</td>\n      <td>1.0</td>\n      <td>82.222408</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0.673923</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>44.011999</td>\n    </tr>\n    <tr>\n      <th>4997</th>\n      <td>0.0</td>\n      <td>1689.256828</td>\n      <td>74.730057</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>0.019575</td>\n      <td>13.579529</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>0.596576</td>\n      <td>2.0</td>\n      <td>86.134989</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.661564</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>22.645691</td>\n    </tr>\n    <tr>\n      <th>4998</th>\n      <td>1.0</td>\n      <td>1469.869266</td>\n      <td>14.525267</td>\n      <td>8.0</td>\n      <td>5.0</td>\n      <td>0.057964</td>\n      <td>79.890496</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>9.0</td>\n      <td>0.528380</td>\n      <td>1.0</td>\n      <td>145.756246</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.553282</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>27.741351</td>\n    </tr>\n    <tr>\n      <th>4999</th>\n      <td>2.0</td>\n      <td>1989.110768</td>\n      <td>102.088126</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>0.105994</td>\n      <td>76.325049</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>6.0</td>\n      <td>0.563023</td>\n      <td>0.0</td>\n      <td>144.471874</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0.557232</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>117.808088</td>\n    </tr>\n  </tbody>\n</table>\n<p>5000 rows × 100 columns</p>\n</div>"
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imputed data frame\n",
    "imputed_df = pd.DataFrame(imputed, columns=df.columns[0:100])\n",
    "imputed_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "outputs": [
    {
     "data": {
      "text/plain": "        QI8KX        EW5XJ       394MJ  5JCY6  N2TG9     MWSMR       M57ER  \\\nuserId                                                                       \n0         2.0   178.411894   64.271156    7.0    7.0  0.342611   79.245015   \n1         2.0    41.058191   67.988225    0.0    3.0  0.504474         NaN   \n2         1.0  1118.457041  147.822393    0.0    NaN  0.780437  134.648108   \n3         1.0  2690.553815  103.377883    3.0    3.0  0.291342  145.199941   \n4         0.0   615.266363   49.694446    1.0    4.0  0.123044   64.328732   \n...       ...          ...         ...    ...    ...       ...         ...   \n4995      2.0   364.680844         NaN    2.0    0.0  0.032761   38.924141   \n4996      1.0          NaN    1.225612    2.0    2.0  0.886880  110.135788   \n4997      0.0  1689.256828         NaN    6.0    0.0  0.019575   13.579529   \n4998      1.0  1469.869266   14.525267    8.0    5.0  0.057964   79.890496   \n4999      2.0  1989.110768  102.088126    3.0    3.0  0.105994   76.325049   \n\n        U0DHH  RWCWO  MAR0D  ...  Y3K0J     P97EB  6IAMA       FQ2EP  PT1HK  \\\nuserId                       ...                                              \n0         0.0    1.0    1.0  ...    6.0  0.996116    2.0    9.397782    2.0   \n1         1.0    0.0    2.0  ...    7.0  0.543821    0.0   93.616651    NaN   \n2         1.0    1.0    2.0  ...    2.0  0.494028    1.0   14.240045    0.0   \n3         2.0    1.0    0.0  ...    4.0  0.001430    0.0   11.934569    1.0   \n4         0.0    1.0    0.0  ...    1.0  0.684642    1.0  131.100466    2.0   \n...       ...    ...    ...  ...    ...       ...    ...         ...    ...   \n4995      2.0    0.0    0.0  ...    NaN  0.750833    2.0  140.076844    2.0   \n4996      2.0    1.0    0.0  ...    NaN  0.297160    1.0   82.222408    1.0   \n4997      1.0    1.0    2.0  ...    2.0  0.596576    2.0   86.134989    2.0   \n4998      2.0    0.0    2.0  ...    9.0  0.528380    1.0  145.756246    0.0   \n4999      NaN    1.0    0.0  ...    6.0  0.563023    0.0  144.471874    2.0   \n\n        AYUOY     WBN7F  HG7C0  TUQX1       B1OIL  \nuserId                                             \n0         0.0       NaN    1.0    NaN  103.285235  \n1         1.0  0.589777    1.0    0.0   21.555428  \n2         1.0  0.572293    1.0    1.0   96.054583  \n3         2.0  0.723056    0.0    1.0   53.042763  \n4         0.0  0.455917    0.0    1.0  104.397814  \n...       ...       ...    ...    ...         ...  \n4995      0.0  0.725573    0.0    2.0    0.668651  \n4996      2.0  0.673923    1.0    2.0   44.011999  \n4997      NaN  0.661564    1.0    0.0   22.645691  \n4998      NaN       NaN    0.0    0.0   27.741351  \n4999      2.0  0.557232    1.0    2.0  117.808088  \n\n[5000 rows x 100 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>QI8KX</th>\n      <th>EW5XJ</th>\n      <th>394MJ</th>\n      <th>5JCY6</th>\n      <th>N2TG9</th>\n      <th>MWSMR</th>\n      <th>M57ER</th>\n      <th>U0DHH</th>\n      <th>RWCWO</th>\n      <th>MAR0D</th>\n      <th>...</th>\n      <th>Y3K0J</th>\n      <th>P97EB</th>\n      <th>6IAMA</th>\n      <th>FQ2EP</th>\n      <th>PT1HK</th>\n      <th>AYUOY</th>\n      <th>WBN7F</th>\n      <th>HG7C0</th>\n      <th>TUQX1</th>\n      <th>B1OIL</th>\n    </tr>\n    <tr>\n      <th>userId</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.0</td>\n      <td>178.411894</td>\n      <td>64.271156</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>0.342611</td>\n      <td>79.245015</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>6.0</td>\n      <td>0.996116</td>\n      <td>2.0</td>\n      <td>9.397782</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>103.285235</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.0</td>\n      <td>41.058191</td>\n      <td>67.988225</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.504474</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>7.0</td>\n      <td>0.543821</td>\n      <td>0.0</td>\n      <td>93.616651</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.589777</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>21.555428</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>1118.457041</td>\n      <td>147.822393</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.780437</td>\n      <td>134.648108</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>0.494028</td>\n      <td>1.0</td>\n      <td>14.240045</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.572293</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>96.054583</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>2690.553815</td>\n      <td>103.377883</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>0.291342</td>\n      <td>145.199941</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>4.0</td>\n      <td>0.001430</td>\n      <td>0.0</td>\n      <td>11.934569</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0.723056</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>53.042763</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>615.266363</td>\n      <td>49.694446</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>0.123044</td>\n      <td>64.328732</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.684642</td>\n      <td>1.0</td>\n      <td>131.100466</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.455917</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>104.397814</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4995</th>\n      <td>2.0</td>\n      <td>364.680844</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.032761</td>\n      <td>38.924141</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.750833</td>\n      <td>2.0</td>\n      <td>140.076844</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.725573</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.668651</td>\n    </tr>\n    <tr>\n      <th>4996</th>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.225612</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0.886880</td>\n      <td>110.135788</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.297160</td>\n      <td>1.0</td>\n      <td>82.222408</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0.673923</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>44.011999</td>\n    </tr>\n    <tr>\n      <th>4997</th>\n      <td>0.0</td>\n      <td>1689.256828</td>\n      <td>NaN</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>0.019575</td>\n      <td>13.579529</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>0.596576</td>\n      <td>2.0</td>\n      <td>86.134989</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>0.661564</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>22.645691</td>\n    </tr>\n    <tr>\n      <th>4998</th>\n      <td>1.0</td>\n      <td>1469.869266</td>\n      <td>14.525267</td>\n      <td>8.0</td>\n      <td>5.0</td>\n      <td>0.057964</td>\n      <td>79.890496</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>9.0</td>\n      <td>0.528380</td>\n      <td>1.0</td>\n      <td>145.756246</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>27.741351</td>\n    </tr>\n    <tr>\n      <th>4999</th>\n      <td>2.0</td>\n      <td>1989.110768</td>\n      <td>102.088126</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>0.105994</td>\n      <td>76.325049</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>6.0</td>\n      <td>0.563023</td>\n      <td>0.0</td>\n      <td>144.471874</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0.557232</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>117.808088</td>\n    </tr>\n  </tbody>\n</table>\n<p>5000 rows × 100 columns</p>\n</div>"
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.columns[0:100]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature Scaling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A brief article detailing information about feature scaling can be found [here](https://towardsdatascience.com/all-about-feature-scaling-bcc0ad75cb35) and [here](https://www.analyticsvidhya.com/blog/2020/04/feature-scaling-machine-learning-normalization-standardization/).\n",
    "\n",
    "Two common methods are normalisation and standardisation. [Normalisation](https://www.geeksforgeeks.org/what-is-data-normalization/) involves bounding our numbers between two values such as 0 and 1. [Standardisation](https://www.sisense.com/glossary/data-standardization/) transforms the data to have zero mean and a variance of 1, making the data unitless.\n",
    "\n",
    "As stated in [this](https://www.geeksforgeeks.org/normalization-vs-standardization/) GeeksforGeeks article, normalisation struggles with outliers. For example, it would be better suited to age data rather than salary data. Standardisation is better suited to data with a Gaussian/normal distribution and is relatively unaffected by outliers.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "outputs": [],
   "source": [
    "# Get the continuous numerical columns in a dataframe\n",
    "def find_continuous_columns(dataframe):\n",
    "\n",
    "    columns = [list(dataframe[i]) for i in dataframe]\n",
    "\n",
    "    uniques = [len(set([i for i in a if pd.notna(i)])) for a in columns] # Num of unique values in a column\n",
    "\n",
    "    continuous_indexes = [i for i, c in enumerate(uniques) if c > 10] # Indexes of continuous columns\n",
    "\n",
    "    # List of column names\n",
    "    con_cols = [dataframe.columns[x] for x in continuous_indexes]\n",
    "\n",
    "    return con_cols # return list of continuous column names"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "def sk_scaling(df, scaling='s'):\n",
    "\n",
    "    if scaling == 's':\n",
    "        scaler = StandardScaler()\n",
    "        scaled = scaler.fit_transform(df)\n",
    "        return scaled\n",
    "\n",
    "    elif scaling == 'n':\n",
    "        scaler = MinMaxScaler()\n",
    "        scaled = scaler.fit_transform(df)\n",
    "        return scaled\n",
    "\n",
    "    else:\n",
    "\n",
    "        print(f'Incorrect scaling parameter')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "outputs": [],
   "source": [
    "# List of column names for continuous columns\n",
    "continuous_df = df[find_continuous_columns(df)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "outputs": [],
   "source": [
    "# Apply Normalised feature scaling\n",
    "scaled_df = sk_scaling(continuous_df, 'n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.05944203, 0.42815548, 0.34261273, ..., 0.92193613, 0.9213182 ,\n        0.76172814],\n       [0.01364084, 0.45295483, 0.50456458, ..., 0.87370724, 0.25267846,\n        0.75417266],\n       [0.3729042 , 0.98558849, 0.78067878, ..., 0.16714741, 0.85365628,\n        0.54980464],\n       ...,\n       [0.56323988,        nan, 0.01939916, ..., 0.70633306, 0.65780965,\n        0.21630349],\n       [0.49008414, 0.09626332, 0.05780914, ...,        nan, 0.04249639,\n        0.62147281],\n       [0.66322748, 0.68046087, 0.1058661 , ..., 0.34451309, 0.81382018,\n        0.69929065]])"
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "execution_count": 220
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Oversampling or Undersampling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Oversampling and undersampling are methods applied to an imbalanced dataset where there is a risk of the minority class being ignored by ML algorithms ([explained here](https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/)).\n",
    "\n",
    "Random oversampling duplicates examples from the minority class in the dataset but can result in overfitting.\n",
    "\n",
    "Random undersampling removes samples from the majority class but can result in the loss of important information.\n",
    "\n",
    "Example implementation of SMOTE oversampling [here](https://beckernick.github.io/oversampling-modeling/) with documentation [here](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html).\n",
    "\n",
    "SMOTE only works for continuous data so we must use SMOTE-NC for mixed data as detailed [here](https://towardsdatascience.com/5-smote-techniques-for-oversampling-your-imbalance-data-b8155bdbe2b5)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "outputs": [],
   "source": [
    "# Good library for this is the imbalanced-learn python library\n",
    "from imblearn.over_sampling import SMOTENC"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "outputs": [],
   "source": [
    "# Create SMOTE instance with some parameters set\n",
    "sm = SMOTENC(0.8, random_state=12)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nSMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [245]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Conduct oversampling\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m X_train_res, y_train_res \u001B[38;5;241m=\u001B[39m \u001B[43msm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_resample\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/GitHub/ThyCa_Classification_UKBB/venv/lib/python3.9/site-packages/imblearn/base.py:77\u001B[0m, in \u001B[0;36mSamplerMixin.fit_resample\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m     75\u001B[0m check_classification_targets(y)\n\u001B[1;32m     76\u001B[0m arrays_transformer \u001B[38;5;241m=\u001B[39m ArraysTransformer(X, y)\n\u001B[0;32m---> 77\u001B[0m X, y, binarize_y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_X_y\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     79\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msampling_strategy_ \u001B[38;5;241m=\u001B[39m check_sampling_strategy(\n\u001B[1;32m     80\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msampling_strategy, y, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampling_type\n\u001B[1;32m     81\u001B[0m )\n\u001B[1;32m     83\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fit_resample(X, y)\n",
      "File \u001B[0;32m~/Desktop/GitHub/ThyCa_Classification_UKBB/venv/lib/python3.9/site-packages/imblearn/base.py:132\u001B[0m, in \u001B[0;36mBaseSampler._check_X_y\u001B[0;34m(self, X, y, accept_sparse)\u001B[0m\n\u001B[1;32m    130\u001B[0m     accept_sparse \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcsr\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcsc\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    131\u001B[0m y, binarize_y \u001B[38;5;241m=\u001B[39m check_target_type(y, indicate_one_vs_all\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m--> 132\u001B[0m X, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maccept_sparse\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    133\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m X, y, binarize_y\n",
      "File \u001B[0;32m~/Desktop/GitHub/ThyCa_Classification_UKBB/venv/lib/python3.9/site-packages/sklearn/base.py:596\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[0;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[1;32m    594\u001B[0m         y \u001B[38;5;241m=\u001B[39m check_array(y, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_y_params)\n\u001B[1;32m    595\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 596\u001B[0m         X, y \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_X_y\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcheck_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    597\u001B[0m     out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[1;32m    599\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m check_params\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mensure_2d\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m):\n",
      "File \u001B[0;32m~/Desktop/GitHub/ThyCa_Classification_UKBB/venv/lib/python3.9/site-packages/sklearn/utils/validation.py:1074\u001B[0m, in \u001B[0;36mcheck_X_y\u001B[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n\u001B[1;32m   1069\u001B[0m         estimator_name \u001B[38;5;241m=\u001B[39m _check_estimator_name(estimator)\n\u001B[1;32m   1070\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1071\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m requires y to be passed, but the target y is None\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1072\u001B[0m     )\n\u001B[0;32m-> 1074\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1075\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1076\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maccept_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1077\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_large_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maccept_large_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1078\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1079\u001B[0m \u001B[43m    \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1080\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1081\u001B[0m \u001B[43m    \u001B[49m\u001B[43mforce_all_finite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_all_finite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1082\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_2d\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_2d\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1083\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_nd\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_nd\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1084\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_min_samples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_min_samples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1085\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_min_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_min_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1086\u001B[0m \u001B[43m    \u001B[49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1087\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mX\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1088\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1090\u001B[0m y \u001B[38;5;241m=\u001B[39m _check_y(y, multi_output\u001B[38;5;241m=\u001B[39mmulti_output, y_numeric\u001B[38;5;241m=\u001B[39my_numeric, estimator\u001B[38;5;241m=\u001B[39mestimator)\n\u001B[1;32m   1092\u001B[0m check_consistent_length(X, y)\n",
      "File \u001B[0;32m~/Desktop/GitHub/ThyCa_Classification_UKBB/venv/lib/python3.9/site-packages/sklearn/utils/validation.py:899\u001B[0m, in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[1;32m    893\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    894\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound array with dim \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m expected <= 2.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    895\u001B[0m             \u001B[38;5;241m%\u001B[39m (array\u001B[38;5;241m.\u001B[39mndim, estimator_name)\n\u001B[1;32m    896\u001B[0m         )\n\u001B[1;32m    898\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m force_all_finite:\n\u001B[0;32m--> 899\u001B[0m         \u001B[43m_assert_all_finite\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    900\u001B[0m \u001B[43m            \u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    901\u001B[0m \u001B[43m            \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    902\u001B[0m \u001B[43m            \u001B[49m\u001B[43mestimator_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    903\u001B[0m \u001B[43m            \u001B[49m\u001B[43mallow_nan\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_all_finite\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mallow-nan\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    904\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    906\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ensure_min_samples \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    907\u001B[0m     n_samples \u001B[38;5;241m=\u001B[39m _num_samples(array)\n",
      "File \u001B[0;32m~/Desktop/GitHub/ThyCa_Classification_UKBB/venv/lib/python3.9/site-packages/sklearn/utils/validation.py:146\u001B[0m, in \u001B[0;36m_assert_all_finite\u001B[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001B[0m\n\u001B[1;32m    124\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    125\u001B[0m             \u001B[38;5;129;01mnot\u001B[39;00m allow_nan\n\u001B[1;32m    126\u001B[0m             \u001B[38;5;129;01mand\u001B[39;00m estimator_name\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    130\u001B[0m             \u001B[38;5;66;03m# Improve the error message on how to handle missing values in\u001B[39;00m\n\u001B[1;32m    131\u001B[0m             \u001B[38;5;66;03m# scikit-learn.\u001B[39;00m\n\u001B[1;32m    132\u001B[0m             msg_err \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    133\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not accept missing values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    134\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    144\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m#estimators-that-handle-nan-values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    145\u001B[0m             )\n\u001B[0;32m--> 146\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg_err)\n\u001B[1;32m    148\u001B[0m \u001B[38;5;66;03m# for object dtype data, we only check for NaNs (GH-13254)\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m X\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m np\u001B[38;5;241m.\u001B[39mdtype(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mobject\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m allow_nan:\n",
      "\u001B[0;31mValueError\u001B[0m: Input X contains NaN.\nSMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "# Conduct oversampling\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature Selection"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Two key feature selection methods being considered here: MRMR & RFE.\n",
    "\n",
    "You could consider feature selection a hyperparameter. Consequently, you can include it as part of a cross validation grid search to obtain optimum hyperparameters for the model in question. Read about it [here](https://medium.com/data-science-reporter/feature-selection-via-grid-search-in-supervised-models-4dc0c43d7ab1).\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cross Validation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Hyperparameter Tuning - Grid searching"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Testing & Evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Explainability"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Preproccessing:\n",
    "\n",
    "- Clean data\n",
    "- Add thyroid cancer\n",
    "- Colum names\n",
    "- Manual feature selection (data leakage - look at mutual information)\n",
    "\n",
    "\n",
    "Pipeline:\n",
    "\n",
    "Test-Train split\n",
    "\n",
    "1. One-Hot encoding (not for random forests & some others)\n",
    "2. Imputation\n",
    "3. Feature scaling (not always)\n",
    "4. Oversampling (not always)\n",
    "5. Model selection\n",
    "6. Cross validation grid search for hyperparameters and feature selection\n",
    "7. Build Model\n",
    "8."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Logging!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}